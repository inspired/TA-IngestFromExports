# BEGIN Use case 1: Ingest from Exporttool

[splunk_exporttool]
INDEXED_EXTRACTIONS = CSV
TIME_FORMAT = %s
TIME_PREFIX = ^
MAX_TIMESTAMP_LOOKAHEAD = 10
TRANSFORMS-csv_field_fix = csv_field_fix
SHOULD_LINEMERGE = false
MAX_EVENTS = 0
TRUNCATE = 0
MAX_DAYS_AGO = 10951
MAX_DAYS_HENCE = 10951
MAX_DIFF_SECS_AGO = 2147483646
MAX_DIFF_SECS_HENCE = 2147483646

# END Use case 1: Ingest from Exporttool

# BEGIN Use case 2: Ingest from Ingest Actions

# No longer required as of Splunk 9.4.2
#[source::....zstd?(.\d+)?]
#unarchive_cmd = zstd --stdout -d
#sourcetype = preprocess-zstd
#NO_BINARY_CHECK = true

#[preprocess-zstd]
#invalid_cause = archive
#is_valid = False
#LEARN_MODEL = false

# NDJSON from Ingest Actions
[rfs_input]
INDEXED_EXTRACTIONS = NONE
TRUNCATE = 0
TRANSFORMS-rfs_ndjson_rewrite = rfs_ndjson_rewrite, rfs_ndjson_write_indexed_fields, rfs_ndjson_null_indexed_fields
LINE_BREAKER = ([\r\n]+)
SHOULD_LINEMERGE = false
disabled = false
pulldown_type = true
TIME_PREFIX = ^{"time":
TIME_FORMAT = %s.%3N

# NDJSON from Ingest Actions keeping the original index in event
[rfs_input_with_index]
INDEXED_EXTRACTIONS = NONE
TRUNCATE = 0
# Use the below TRANSFORMS if you want to keep the original index. In this case, define a lastChanceIndex = <index name> in indexes.conf as well to capture events going to indexes that do not exist.
TRANSFORMS-rfs_ndjson_rewrite = rfs_ndjson_rewrite_with_index, rfs_ndjson_write_indexed_fields, rfs_ndjson_null_indexed_fields
LINE_BREAKER = ([\r\n]+)
SHOULD_LINEMERGE = false
disabled = false
pulldown_type = true
TIME_PREFIX = ^{"time":
TIME_FORMAT = %s.%3N

# OPTIONAL: Passthrough to EP (UF/HF -> EP -> Indexer)
[rfs_input_with_index_ep]
INDEXED_EXTRACTIONS = NONE
TRUNCATE = 0
LINE_BREAKER = ([\r\n]+)
SHOULD_LINEMERGE = false
disabled = false
pulldown_type = true
TIME_PREFIX = ^{"time":
TIME_FORMAT = %s.%3N

# END Use case 2: Ingest from Ingest Actions

# BEGIN Use case 3: Ingest from Splunk JSON Export
#
[index_splunk_json_export]
# INDEXED_EXTRACTIONS = JSON is not a good idea because we will not be able to remove 2nd level JSON keys like result.key1, result.key2 with null() without explicitly listing each key. result:=null() won't work, so we avoid this problem by not ingesting it as JSON.
TRUNCATE = 0
TRANSFORMS-reformat_splunk_json_export = reformat_splunk_json_export
LINE_BREAKER = ([\r\n]+)
SHOULD_LINEMERGE = false

[index_splunk_json_export_with_index]
# INDEXED_EXTRACTIONS = JSON is not a good idea because we will not be able to remove 2nd level JSON keys like result.key1, result.key2 with null() without explicitly listing each key. result:=null() won't work, so we avoid this problem by not ingesting it as JSON.
TRUNCATE = 0
# Use the below TRANSFORMS if you want to keep the original index. In this case, define a lastChanceIndex = <index name> in indexes.conf as well to capture events going to indexes that do not exist.
TRANSFORMS-reformat_splunk_json_export_with_index = reformat_splunk_json_export_with_index
LINE_BREAKER = ([\r\n]+)
SHOULD_LINEMERGE = false

# END Use case 3: Ingest from Splunk JSON Export
